#!/usr/bin/env python3
"""
OpenAI API å…¼å®¹æ€§æµ‹è¯•å®¢æˆ·ç«¯
"""
from openai import OpenAI

def test_with_openai_client():
    """ä½¿ç”¨ OpenAI å®¢æˆ·ç«¯åº“æµ‹è¯•"""
    print("ğŸ§ª Testing with OpenAI client library...")
    
    # åˆ›å»ºå®¢æˆ·ç«¯ï¼ŒæŒ‡å‘æˆ‘ä»¬çš„æœ¬åœ°API
    client = OpenAI(
        base_url="http://127.0.0.1:8000/v1",
        api_key="dummy-key"  # æˆ‘ä»¬çš„APIä¸éœ€è¦çœŸå®çš„key
    )
    
    try:
        # æµ‹è¯•èŠå¤©å®Œæˆ
        print("ğŸ’¬ Testing chat completion...")
        response = client.chat.completions.create(
            model="Qwen/Qwen3-8B-AWQ",
            messages=[
                {"role": "user", "content": "ä½ å¥½ï¼è¯·ç”¨ä¸­æ–‡ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚"}
            ],
            max_tokens=100,
            temperature=0.7
        )
        
        print(f"âœ… Response received:")
        print(f"Model: {response.model}")
        print(f"Content: {response.choices[0].message.content}")
        print(f"Usage: {response.usage}")
        
        # æµ‹è¯•æµå¼å“åº”
        print("\nğŸŒŠ Testing streaming...")
        stream = client.chat.completions.create(
            model="Qwen/Qwen3-8B-AWQ",
            messages=[
                {"role": "user", "content": "ä»1æ•°åˆ°5ï¼Œæ¯ä¸ªæ•°å­—ä¸€è¡Œ"}
            ],
            max_tokens=50,
            temperature=0.7,
            stream=True
        )
        
        print("Stream response:")
        for chunk in stream:
            if chunk.choices[0].delta.content:
                print(chunk.choices[0].delta.content, end='', flush=True)
        print("\nâœ… Streaming completed")
        
        return True
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        return False

if __name__ == "__main__":
    print("ğŸš€ Starting OpenAI compatibility test...\n")
    test_with_openai_client()
    print("\nâœ… Test completed!")
